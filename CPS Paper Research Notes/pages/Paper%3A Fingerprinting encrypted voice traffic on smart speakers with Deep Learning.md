year-published:: #[[Published 2020]] 
paper-type:: 
source:: [ACM](https://dl.acm.org/doi/10.1145/3395351.3399357)

- ![Fingerprinting Encrypted Voice Traffic on Smart Speakers with Deep Learning](../assets/Fingerprinting_Voice_Traffic_1733852829714_0.pdf)
- Summary
	- This attack allows an adversary to eavesdrop on both outgoing and 
	  incoming encrypted voice traffic to infer which voice command a user has
	   issued, even without decrypting the traffic.
	- Adversarial Model
	  collapsed:: true
		- **Attacker's Position**:
			- The attacker can be on the victim's WiFi network or at a compromised WiFi 
			  access point, allowing them to monitor the traffic between the smart 
			  speaker and its cloud server.
		- **Capabilities**:
			- The attacker cannot decrypt the encrypted packets. They also do not have the ability 
			  to drop, change, or inject packets into the traffic.
		- **Knowledge Assumptions**:
			- The attacker is assumed to know the model of the smart speaker (e.g., Amazon
			  Echo or Google Home) and can infer the IP addresses of both the smart speaker and the server it communicates with.
		- **Traffic Analysis**:
			- The attacker can analyze the traffic based on side-channel information, which includes the size, direction, and order of the encrypted packets. This information can be used to infer the user's voice commands without needing to decrypt the actual content of the traffic.
		- **Traffic Trace**:
			- The attacker can capture a traffic trace that includes all packets for a voice command and its corresponding response, allowing them to analyze the patterns in the traffic.
	- Attack Methodology
	  collapsed:: true
		- **Data Collection**:
			- The researchers collected two datasets from Amazon Echo and Google Home 
			  smart speakers. They gathered a significant amount of encrypted traffic by issuing various voice commands and capturing the corresponding network packets. The datasets included both closed-world (where a specific set of commands is known) and open-world settings (where commands outside the known set are also considered).
		- **Traffic Analysis**:
			- The attack leverages the characteristics of the encrypted traffic, such as packet 
			  sizes, timing, and the order of packets. Even though the traffic is encrypted, the patterns in the traffic can reveal information about the commands being executed. The researchers used deep learning techniques to analyze these patterns.
		- **Neural Network Models**:
			- The authors implemented several neural network architectures, including Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM) networks, and Stacked Autoencoders (SAE). These models were trained on the collected traffic data to learn the distinctive patterns associated with different voice commands.
	- Countermeasures
	  collapsed:: true
		- **Adaptive Padding**:
			- This technique involves adding dummy packets to the traffic to obfuscate the actual communication patterns. By introducing variability in the packet sizes and timing, it becomes more challenging for an attacker to discern the true nature of the traffic and infer the specific voice commands being issued.
		- **Differential Privacy**:
			- The authors suggest incorporating differential privacy mechanisms into the data transmission process. This approach adds noise to the data being sent, which helps to protect the privacy of the user's voice commands. By ensuring that the output of the system does not reveal too much information about any individual input, differential privacy can significantly reduce the risk of successful fingerprinting attacks.
		- **Traffic Shaping**:
			- Implementing traffic shaping techniques can help manage the flow of data packets in a
			  way that obscures the patterns that attackers might exploit. This can involve controlling the timing and size of packets to make it harder for adversaries to analyze the traffic effectively.
		- **Increased Latency**:
			- The paper notes that while increasing the privacy parameter (epsilon, ùúñ) in differential privacy can lead to higher latency, it also reduces the bandwidth overhead. By accepting a certain level of latency, the system can enhance privacy protection, making it more difficult for attackers to accurately infer voice commands.
		- **Modeling Prior Probabilities**:
			- The authors highlight the importance of accurately modeling prior probabilities of different voice commands. By considering the context in which commands are issued (e.g., time of year, user behavior), the system can better defend against attacks that rely on uniform prior assumptions.
		- **Future Work**:
			- The paper also suggests that future research could explore additional defenses, such as leveraging packet timing information and studying the impact of human voices on the attack's effectiveness
- References
	- [[Paper: Peek-a-Boo: Seeing Encrypted Home Activities]]